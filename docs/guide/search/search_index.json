{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"S3verless Documentation","text":"<p>Welcome to S3verless - the Python framework that uses S3 as your database.</p>"},{"location":"index.html#quick-install","title":"Quick Install","text":"<pre><code>pip install s3verless\n</code></pre>"},{"location":"index.html#guides","title":"Guides","text":"<ul> <li> <p> Getting Started</p> <p>Set up your first S3verless project in minutes</p> </li> <li> <p> Models</p> <p>Define data models with validation and indexes</p> </li> <li> <p> Queries</p> <p>Filter, sort, and paginate your data</p> </li> <li> <p> Authentication</p> <p>JWT auth, rate limiting, and user management</p> </li> <li> <p> Relationships</p> <p>Connect models with foreign keys</p> </li> <li> <p> Migrations</p> <p>Evolve your data schema safely</p> </li> <li> <p> Caching</p> <p>Speed up your app with in-memory caching</p> </li> <li> <p> File Storage</p> <p>Handle uploads with presigned URLs</p> </li> <li> <p> Testing</p> <p>Test without external dependencies</p> </li> <li> <p> Deployment</p> <p>Deploy to Lambda, Docker, or LocalStack</p> </li> </ul>"},{"location":"index.html#api-reference","title":"API Reference","text":"<p>Full reference for all classes and functions: API Reference</p>"},{"location":"index.html#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>PyPI Package</li> <li>Landing Page</li> </ul>"},{"location":"api-reference.html","title":"S3verless API Reference","text":"<p>Complete API documentation for all public classes and functions.</p>"},{"location":"api-reference.html#core-module","title":"Core Module","text":""},{"location":"api-reference.html#bases3model","title":"BaseS3Model","text":"<p>Base class for all S3-stored models. Inherit from this to create your data models.</p> <pre><code>from s3verless.core.base import BaseS3Model\n\nclass Product(BaseS3Model):\n    _plural_name = \"products\"\n    _unique_fields = [\"sku\"]\n    _indexed_fields = [\"category\", \"price\"]\n\n    name: str\n    sku: str\n    price: float\n    category: str\n</code></pre> <p>Class Variables: - <code>_plural_name: str</code> - Plural name for API routes (default: lowercase class name) - <code>_unique_fields: list[str]</code> - Fields that must be unique across all instances - <code>_indexed_fields: list[str]</code> - Fields to index for faster queries - <code>_enable_api: bool</code> - Whether to auto-generate CRUD API (default: True)</p> <p>Instance Attributes: - <code>id: UUID</code> - Auto-generated unique identifier - <code>created_at: datetime</code> - Creation timestamp (UTC) - <code>updated_at: datetime</code> - Last update timestamp (UTC)</p> <p>Methods:</p> <pre><code>@classmethod\ndef get_s3_prefix(cls) -&gt; str:\n    \"\"\"Get the S3 prefix for this model.\"\"\"\n\n@classmethod\ndef get_s3_key(cls, object_id: UUID) -&gt; str:\n    \"\"\"Get the full S3 key for an object.\"\"\"\n\ndef touch(self) -&gt; None:\n    \"\"\"Update the updated_at timestamp.\"\"\"\n\n@property\ndef s3_key(self) -&gt; str:\n    \"\"\"Get the S3 key for this instance.\"\"\"\n</code></pre>"},{"location":"api-reference.html#s3dataservice","title":"S3DataService","text":"<p>Generic service for CRUD operations on S3-stored models.</p> <pre><code>from s3verless.core.service import S3DataService\n\nservice = S3DataService(Product, \"my-bucket\")\n</code></pre> <p>Constructor: <pre><code>S3DataService(model: Type[T], bucket_name: str)\n</code></pre></p> <p>Methods:</p> <pre><code>async def get(self, s3_client, obj_id: UUID) -&gt; T | None:\n    \"\"\"Retrieve an object by ID.\"\"\"\n\nasync def create(self, s3_client, data: BaseModel) -&gt; T:\n    \"\"\"Create a new object. Validates unique fields.\"\"\"\n\nasync def update(self, s3_client, obj_id: UUID, update_data: BaseModel) -&gt; T | None:\n    \"\"\"Update an existing object.\"\"\"\n\nasync def delete(self, s3_client, obj_id: UUID) -&gt; bool:\n    \"\"\"Delete an object by ID.\"\"\"\n\nasync def exists(self, s3_client, obj_id: UUID) -&gt; bool:\n    \"\"\"Check if an object exists.\"\"\"\n\nasync def list_by_prefix(\n    self, s3_client, limit: int = 100, marker: str | None = None\n) -&gt; tuple[list[T], str | None]:\n    \"\"\"List objects with pagination.\"\"\"\n\nasync def paginate(\n    self, s3_client, page: int = 1, page_size: int = 20\n) -&gt; dict:\n    \"\"\"List objects with pagination metadata.\"\"\"\n</code></pre>"},{"location":"api-reference.html#query","title":"Query","text":"<p>Fluent query builder for filtering and sorting S3 data.</p> <pre><code>from s3verless.core.query import Query\n\nresults = await (\n    Query(Product, s3_client, \"my-bucket\")\n    .filter(category=\"electronics\")\n    .filter(price__gt=100)\n    .order_by(\"-price\")\n    .limit(10)\n    .all()\n)\n</code></pre> <p>Constructor: <pre><code>Query(model_class: Type[T], s3_client, bucket_name: str)\n</code></pre></p> <p>Filter Operators: - <code>field=value</code> - Exact match - <code>field__eq=value</code> - Equal - <code>field__ne=value</code> - Not equal - <code>field__gt=value</code> - Greater than - <code>field__gte=value</code> - Greater than or equal - <code>field__lt=value</code> - Less than - <code>field__lte=value</code> - Less than or equal - <code>field__in=[values]</code> - In list - <code>field__nin=[values]</code> - Not in list - <code>field__contains=value</code> - String contains (case-sensitive) - <code>field__icontains=value</code> - String contains (case-insensitive) - <code>field__startswith=value</code> - String starts with - <code>field__endswith=value</code> - String ends with - <code>field__isnull=True/False</code> - Is null/not null</p> <p>Methods:</p> <pre><code>def filter(self, **kwargs) -&gt; Query[T]:\n    \"\"\"Add filter conditions.\"\"\"\n\ndef exclude(self, **kwargs) -&gt; Query[T]:\n    \"\"\"Exclude items matching conditions.\"\"\"\n\ndef order_by(self, field: str) -&gt; Query[T]:\n    \"\"\"Sort results. Prefix with '-' for descending.\"\"\"\n\ndef limit(self, n: int) -&gt; Query[T]:\n    \"\"\"Limit number of results.\"\"\"\n\ndef offset(self, n: int) -&gt; Query[T]:\n    \"\"\"Skip first n results.\"\"\"\n\ndef select(self, *fields: str) -&gt; Query[T]:\n    \"\"\"Select specific fields only.\"\"\"\n\ndef prefetch_related(self, *relations: str) -&gt; Query[T]:\n    \"\"\"Prefetch related objects.\"\"\"\n\nasync def all(self) -&gt; list[T]:\n    \"\"\"Execute query and return all results.\"\"\"\n\nasync def first(self) -&gt; T | None:\n    \"\"\"Return first result or None.\"\"\"\n\nasync def get(self) -&gt; T:\n    \"\"\"Return exactly one result. Raises if 0 or &gt;1.\"\"\"\n\nasync def count(self) -&gt; int:\n    \"\"\"Count matching objects.\"\"\"\n\nasync def exists(self) -&gt; bool:\n    \"\"\"Check if any matching objects exist.\"\"\"\n\nasync def paginate(self, page: int = 1, page_size: int = 20) -&gt; QueryResult[T]:\n    \"\"\"Get paginated results with metadata.\"\"\"\n</code></pre>"},{"location":"api-reference.html#s3clientmanager","title":"S3ClientManager","text":"<p>Singleton manager for S3 client instances with connection pooling.</p> <pre><code>from s3verless.core.client import S3ClientManager\n\nmanager = S3ClientManager(settings)\n</code></pre> <p>Methods:</p> <pre><code>def get_sync_client(self) -&gt; BaseClient:\n    \"\"\"Get a synchronous boto3 S3 client.\"\"\"\n\n@asynccontextmanager\nasync def get_async_client(self) -&gt; AsyncIterator[AioBaseClient]:\n    \"\"\"Get an async S3 client from the pool.\"\"\"\n\ndef stats(self) -&gt; dict:\n    \"\"\"Get client pool statistics.\"\"\"\n</code></pre>"},{"location":"api-reference.html#auth-module","title":"Auth Module","text":""},{"location":"api-reference.html#s3authservice","title":"S3AuthService","text":"<p>Complete authentication service with JWT tokens and user management.</p> <pre><code>from s3verless.auth.service import S3AuthService\n\nauth = S3AuthService(settings)\n</code></pre> <p>Constructor: <pre><code>S3AuthService(\n    settings: S3verlessSettings | None = None,\n    secret_key: str | None = None,\n    algorithm: str = \"HS256\",\n    access_token_expire_minutes: int = 30,\n    refresh_token_expire_days: int = 7,\n    bucket_name: str | None = None,\n)\n</code></pre></p> <p>User Management:</p> <pre><code>async def create_user(\n    self, s3_client, username: str, email: str, password: str,\n    full_name: str | None = None\n) -&gt; S3User:\n    \"\"\"Create a new user.\"\"\"\n\nasync def get_user_by_username(self, s3_client, username: str) -&gt; S3User | None:\n    \"\"\"Find user by username.\"\"\"\n\nasync def get_user_by_email(self, s3_client, email: str) -&gt; S3User | None:\n    \"\"\"Find user by email.\"\"\"\n\nasync def authenticate_user(\n    self, s3_client, username: str, password: str\n) -&gt; S3User | None:\n    \"\"\"Authenticate with username/password.\"\"\"\n</code></pre> <p>Token Management:</p> <pre><code>async def create_token_pair(\n    self, s3_client, user: S3User,\n    device_info: str | None = None,\n    ip_address: str | None = None,\n) -&gt; dict:\n    \"\"\"Create access and refresh token pair.\"\"\"\n\nasync def refresh_access_token(self, s3_client, refresh_token: str) -&gt; dict:\n    \"\"\"Get new access token using refresh token.\"\"\"\n\nasync def revoke_refresh_token(self, s3_client, refresh_token: str) -&gt; bool:\n    \"\"\"Revoke a specific refresh token.\"\"\"\n\nasync def revoke_all_user_tokens(self, s3_client, user_id: UUID) -&gt; int:\n    \"\"\"Revoke all tokens for a user.\"\"\"\n\nasync def cleanup_expired_tokens(self, s3_client) -&gt; int:\n    \"\"\"Remove expired/revoked tokens.\"\"\"\n</code></pre> <p>Password Utilities:</p> <pre><code>def get_password_hash(self, password: str) -&gt; str:\n    \"\"\"Hash a password using bcrypt.\"\"\"\n\ndef verify_password(self, plain_password: str, hashed_password: str) -&gt; bool:\n    \"\"\"Verify password against hash.\"\"\"\n\ndef validate_password(self, password: str) -&gt; tuple[bool, str]:\n    \"\"\"Validate password strength.\"\"\"\n</code></pre>"},{"location":"api-reference.html#tokenblacklist","title":"TokenBlacklist","text":"<p>In-memory + S3 token blacklist for immediate revocation.</p> <pre><code>from s3verless.auth.blacklist import TokenBlacklist\n\nblacklist = TokenBlacklist(bucket_name)\n</code></pre> <p>Methods:</p> <pre><code>async def add(self, s3_client, token_jti: str, expires_at: datetime) -&gt; None:\n    \"\"\"Add token to blacklist.\"\"\"\n\nasync def is_blacklisted(self, s3_client, token_jti: str) -&gt; bool:\n    \"\"\"Check if token is blacklisted.\"\"\"\n\nasync def cleanup(self, s3_client) -&gt; int:\n    \"\"\"Remove expired entries.\"\"\"\n</code></pre>"},{"location":"api-reference.html#ratelimiter","title":"RateLimiter","text":"<p>Per-endpoint rate limiting with configurable limits.</p> <pre><code>from s3verless.auth.rate_limit import RateLimiter\n\nlimiter = RateLimiter(\n    limits={\"login\": RateLimit(10, 60)},\n    trusted_proxies=[\"10.0.0.1\"],\n    trust_x_forwarded_for=True,\n)\n</code></pre> <p>Methods:</p> <pre><code>async def is_rate_limited(\n    self, request, endpoint: str | None = None\n) -&gt; tuple[bool, dict]:\n    \"\"\"Check if request is rate limited.\"\"\"\n\ndef get_rate_limit_headers(self, info: dict) -&gt; dict:\n    \"\"\"Get rate limit headers for response.\"\"\"\n</code></pre>"},{"location":"api-reference.html#cache-module","title":"Cache Module","text":""},{"location":"api-reference.html#cachebackend-abstract","title":"CacheBackend (Abstract)","text":"<p>Base class for cache implementations.</p> <pre><code>async def get(self, key: str) -&gt; Any | None\nasync def set(self, key: str, value: Any, ttl: int | None = None) -&gt; None\nasync def delete(self, key: str) -&gt; bool\nasync def exists(self, key: str) -&gt; bool\nasync def clear(self) -&gt; None\nasync def delete_pattern(self, pattern: str) -&gt; int\n</code></pre>"},{"location":"api-reference.html#inmemorycache","title":"InMemoryCache","text":"<p>Simple in-memory cache with TTL and size limits.</p> <pre><code>from s3verless.cache.memory import InMemoryCache\n\ncache = InMemoryCache(default_ttl=300, max_size=1000)\n</code></pre>"},{"location":"api-reference.html#lrucache","title":"LRUCache","text":"<p>LRU eviction cache with hit rate tracking.</p> <pre><code>from s3verless.cache.memory import LRUCache\n\ncache = LRUCache(max_size=1000, default_ttl=300)\n</code></pre>"},{"location":"api-reference.html#compositecache","title":"CompositeCache","text":"<p>Multi-tier cache that chains backends.</p> <pre><code>from s3verless.cache.composite import CompositeCache\n\ncache = CompositeCache([\n    LRUCache(max_size=100, default_ttl=60),\n    InMemoryCache(max_size=1000, default_ttl=300),\n])\n</code></pre>"},{"location":"api-reference.html#storage-module","title":"Storage Module","text":""},{"location":"api-reference.html#presigneduploadservice","title":"PresignedUploadService","text":"<p>Generate presigned URLs for direct S3 uploads.</p> <pre><code>from s3verless.storage.uploads import PresignedUploadService, UploadConfig\n\nconfig = UploadConfig(\n    max_file_size=10 * 1024 * 1024,\n    allowed_content_types=[\"image/jpeg\", \"image/png\"],\n    expiration_seconds=3600,\n)\nservice = PresignedUploadService(\"my-bucket\", config)\n</code></pre> <p>Methods:</p> <pre><code>async def generate_upload_url(\n    self, s3_client, filename: str,\n    content_type: str | None = None,\n    metadata: dict | None = None,\n) -&gt; dict:\n    \"\"\"Generate presigned URL for upload.\"\"\"\n\nasync def generate_download_url(\n    self, s3_client, s3_key: str,\n    filename: str | None = None,\n    expires_in: int | None = None,\n) -&gt; str:\n    \"\"\"Generate presigned URL for download.\"\"\"\n\nasync def confirm_upload(\n    self, s3_client, s3_key: str, uploaded_by: UUID | None = None\n) -&gt; UploadedFile | None:\n    \"\"\"Confirm upload and create file record.\"\"\"\n\nasync def delete_file(self, s3_client, s3_key: str) -&gt; bool:\n    \"\"\"Delete a file from S3.\"\"\"\n</code></pre>"},{"location":"api-reference.html#fastapi-module","title":"FastAPI Module","text":""},{"location":"api-reference.html#s3verless","title":"S3verless","text":"<p>Main application class with auto-configuration.</p> <pre><code>from s3verless.fastapi.app import S3verless\n\napp_builder = S3verless(\n    settings=settings,\n    title=\"My API\",\n    enable_admin=True,\n    model_packages=[\"myapp.models\"],\n)\napp = app_builder.create_app()\n</code></pre> <p>Constructor: <pre><code>S3verless(\n    settings: S3verlessSettings | None = None,\n    title: str = \"S3verless API\",\n    description: str = \"API powered by S3verless\",\n    version: str = \"1.0.0\",\n    enable_admin: bool = True,\n    model_packages: list[str] | None = None,\n    auto_discover: bool = True,\n)\n</code></pre></p>"},{"location":"api-reference.html#migrations-module","title":"Migrations Module","text":""},{"location":"api-reference.html#migration","title":"Migration","text":"<p>Define data migrations.</p> <pre><code>from s3verless.migrations.base import Migration\n\nmigration = Migration(\n    version=\"0001\",\n    model_name=\"Product\",\n    description=\"Add discount field\",\n    apply=lambda data: {**data, \"discount\": 0},\n    rollback=lambda data: {k: v for k, v in data.items() if k != \"discount\"},\n    reversible=True,\n)\n</code></pre>"},{"location":"api-reference.html#migrationrunner","title":"MigrationRunner","text":"<p>Execute migrations.</p> <pre><code>from s3verless.migrations.runner import MigrationRunner\n\nrunner = MigrationRunner(s3_client, \"my-bucket\", Path(\"./migrations\"))\nresults = await runner.run_pending()\n</code></pre>"},{"location":"api-reference.html#testing-module","title":"Testing Module","text":""},{"location":"api-reference.html#inmemorys3","title":"InMemoryS3","text":"<p>Mock S3 client for testing.</p> <pre><code>from s3verless.testing.mocks import InMemoryS3, mock_s3_client\n\n# Direct usage\ns3 = InMemoryS3()\nawait s3.put_object(Bucket=\"test\", Key=\"data.json\", Body=b'{}')\n\n# Context manager\nwith mock_s3_client() as s3:\n    await s3.create_bucket(Bucket=\"test\")\n</code></pre>"},{"location":"api-reference.html#settings","title":"Settings","text":""},{"location":"api-reference.html#s3verlesssettings","title":"S3verlessSettings","text":"<p>Configuration via environment variables or direct instantiation.</p> <pre><code>from s3verless.core.settings import S3verlessSettings\n\nsettings = S3verlessSettings(\n    aws_bucket_name=\"my-bucket\",\n    aws_region=\"us-east-1\",\n    secret_key=\"your-jwt-secret\",\n)\n</code></pre> <p>Environment Variables: - <code>AWS_BUCKET_NAME</code> - S3 bucket name - <code>AWS_REGION</code> - AWS region - <code>AWS_ACCESS_KEY_ID</code> - AWS credentials - <code>AWS_SECRET_ACCESS_KEY</code> - AWS credentials - <code>AWS_ENDPOINT_URL</code> - Custom endpoint (LocalStack) - <code>SECRET_KEY</code> - JWT signing key - <code>ALGORITHM</code> - JWT algorithm (default: HS256) - <code>ACCESS_TOKEN_EXPIRE_MINUTES</code> - Token expiry (default: 30) - <code>S3_BASE_PATH</code> - Base path prefix in bucket</p>"},{"location":"guide-auth.html","title":"Authentication Guide","text":"<p>Complete authentication with JWT tokens, refresh tokens, rate limiting, and authorization.</p>"},{"location":"guide-auth.html#setup","title":"Setup","text":""},{"location":"guide-auth.html#configure-settings","title":"Configure Settings","text":"<pre><code>from s3verless.core.settings import S3verlessSettings\n\nsettings = S3verlessSettings(\n    aws_bucket_name=\"my-bucket\",\n    secret_key=\"your-super-secret-key-min-32-chars\",\n    algorithm=\"HS256\",\n    access_token_expire_minutes=30,\n    refresh_token_expire_days=7,\n)\n</code></pre>"},{"location":"guide-auth.html#initialize-auth-service","title":"Initialize Auth Service","text":"<pre><code>from s3verless.auth.service import S3AuthService\n\nauth = S3AuthService(settings)\n</code></pre>"},{"location":"guide-auth.html#user-management","title":"User Management","text":""},{"location":"guide-auth.html#create-user","title":"Create User","text":"<pre><code>user = await auth.create_user(\n    s3_client,\n    username=\"john\",\n    email=\"john@example.com\",\n    password=\"SecurePass123!\",\n    full_name=\"John Doe\",\n)\n</code></pre>"},{"location":"guide-auth.html#password-requirements","title":"Password Requirements","text":"<p>Default requirements: - Minimum 8 characters - At least one uppercase letter - At least one lowercase letter - At least one digit</p>"},{"location":"guide-auth.html#find-users","title":"Find Users","text":"<pre><code># By username\nuser = await auth.get_user_by_username(s3_client, \"john\")\n\n# By email\nuser = await auth.get_user_by_email(s3_client, \"john@example.com\")\n\n# By ID\nuser = await auth.get_user_by_id(s3_client, user_id)\n</code></pre>"},{"location":"guide-auth.html#authentication","title":"Authentication","text":""},{"location":"guide-auth.html#login","title":"Login","text":"<pre><code>user = await auth.authenticate_user(s3_client, \"john\", \"SecurePass123!\")\nif user:\n    tokens = await auth.create_token_pair(\n        s3_client,\n        user,\n        device_info=\"Web Browser\",\n        ip_address=request.client.host,\n    )\n    # Returns: {access_token, refresh_token, token_type, expires_in}\n</code></pre>"},{"location":"guide-auth.html#refresh-tokens","title":"Refresh Tokens","text":"<pre><code>new_tokens = await auth.refresh_access_token(s3_client, refresh_token)\n</code></pre>"},{"location":"guide-auth.html#logout","title":"Logout","text":"<pre><code># Revoke single token\nawait auth.revoke_refresh_token(s3_client, refresh_token)\n\n# Revoke all user tokens (logout everywhere)\nawait auth.revoke_all_user_tokens(s3_client, user.id)\n</code></pre>"},{"location":"guide-auth.html#fastapi-integration","title":"FastAPI Integration","text":""},{"location":"guide-auth.html#dependencies","title":"Dependencies","text":"<pre><code>from fastapi import Depends, HTTPException\nfrom fastapi.security import OAuth2PasswordBearer\n\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"auth/login\")\n\nasync def get_current_user(\n    token: str = Depends(oauth2_scheme),\n    s3_client = Depends(get_s3_client),\n    auth: S3AuthService = Depends(get_auth_service),\n):\n    try:\n        payload = auth.decode_token(token)\n        user = await auth.get_user_by_username(s3_client, payload[\"sub\"])\n        if not user or not user.is_active:\n            raise HTTPException(401, \"Invalid credentials\")\n        return user\n    except Exception:\n        raise HTTPException(401, \"Invalid credentials\")\n</code></pre>"},{"location":"guide-auth.html#protected-routes","title":"Protected Routes","text":"<pre><code>@app.get(\"/me\")\nasync def get_profile(user: S3User = Depends(get_current_user)):\n    return user\n\n@app.put(\"/me\")\nasync def update_profile(\n    data: UpdateProfile,\n    user: S3User = Depends(get_current_user),\n    s3_client = Depends(get_s3_client),\n):\n    # Update user...\n    pass\n</code></pre>"},{"location":"guide-auth.html#admin-only-routes","title":"Admin-Only Routes","text":"<pre><code>async def require_admin(user: S3User = Depends(get_current_user)):\n    if not user.is_admin:\n        raise HTTPException(403, \"Admin access required\")\n    return user\n\n@app.get(\"/admin/users\")\nasync def list_users(admin: S3User = Depends(require_admin)):\n    # Admin-only logic...\n    pass\n</code></pre>"},{"location":"guide-auth.html#rate-limiting","title":"Rate Limiting","text":""},{"location":"guide-auth.html#setup_1","title":"Setup","text":"<pre><code>from s3verless.auth.rate_limit import RateLimiter, RateLimit\n\nlimiter = RateLimiter(\n    limits={\n        \"login\": RateLimit(max_requests=5, window_seconds=60),\n        \"api\": RateLimit(max_requests=100, window_seconds=60),\n    },\n    trusted_proxies=[\"10.0.0.1\"],  # Load balancer IPs\n    trust_x_forwarded_for=True,\n)\n</code></pre>"},{"location":"guide-auth.html#apply-to-routes","title":"Apply to Routes","text":"<pre><code>@app.post(\"/auth/login\")\nasync def login(request: Request, credentials: LoginRequest):\n    is_limited, info = await limiter.is_rate_limited(request, \"login\")\n    if is_limited:\n        raise HTTPException(\n            429,\n            \"Too many requests\",\n            headers=limiter.get_rate_limit_headers(info),\n        )\n    # Login logic...\n</code></pre>"},{"location":"guide-auth.html#middleware","title":"Middleware","text":"<pre><code>@app.middleware(\"http\")\nasync def rate_limit_middleware(request: Request, call_next):\n    is_limited, info = await limiter.is_rate_limited(request, \"api\")\n    if is_limited:\n        return JSONResponse(\n            status_code=429,\n            content={\"detail\": \"Rate limit exceeded\"},\n            headers=limiter.get_rate_limit_headers(info),\n        )\n    response = await call_next(request)\n    return response\n</code></pre>"},{"location":"guide-auth.html#token-blacklisting","title":"Token Blacklisting","text":"<p>For immediate token revocation:</p> <pre><code>from s3verless.auth.blacklist import TokenBlacklist\n\nblacklist = TokenBlacklist(bucket_name)\n\n# Add to blacklist\nawait blacklist.add(s3_client, token_jti, expires_at)\n\n# Check in authentication\nasync def get_current_user(token: str = Depends(oauth2_scheme)):\n    payload = auth.decode_token(token)\n    if await blacklist.is_blacklisted(s3_client, payload.get(\"jti\")):\n        raise HTTPException(401, \"Token revoked\")\n    # Continue authentication...\n</code></pre>"},{"location":"guide-auth.html#session-management","title":"Session Management","text":""},{"location":"guide-auth.html#view-active-sessions","title":"View Active Sessions","text":"<pre><code>sessions = await auth.get_user_active_sessions(s3_client, user.id)\n# Returns: [{id, device_info, ip_address, created_at, expires_at}, ...]\n</code></pre>"},{"location":"guide-auth.html#cleanup-expired-tokens","title":"Cleanup Expired Tokens","text":"<p>Run periodically:</p> <pre><code>deleted_count = await auth.cleanup_expired_tokens(s3_client)\n</code></pre>"},{"location":"guide-auth.html#complete-auth-router-example","title":"Complete Auth Router Example","text":"<pre><code>from fastapi import APIRouter, Depends, HTTPException\nfrom fastapi.security import OAuth2PasswordRequestForm\n\nrouter = APIRouter(prefix=\"/auth\", tags=[\"auth\"])\n\n@router.post(\"/register\")\nasync def register(\n    username: str,\n    email: str,\n    password: str,\n    s3_client = Depends(get_s3_client),\n    auth: S3AuthService = Depends(get_auth_service),\n):\n    try:\n        user = await auth.create_user(s3_client, username, email, password)\n        return {\"message\": \"User created\", \"user_id\": str(user.id)}\n    except S3ValidationError as e:\n        raise HTTPException(400, str(e))\n\n@router.post(\"/login\")\nasync def login(\n    form_data: OAuth2PasswordRequestForm = Depends(),\n    s3_client = Depends(get_s3_client),\n    auth: S3AuthService = Depends(get_auth_service),\n):\n    user = await auth.authenticate_user(\n        s3_client, form_data.username, form_data.password\n    )\n    if not user:\n        raise HTTPException(401, \"Invalid credentials\")\n\n    return await auth.create_token_pair(s3_client, user)\n\n@router.post(\"/refresh\")\nasync def refresh(\n    refresh_token: str,\n    s3_client = Depends(get_s3_client),\n    auth: S3AuthService = Depends(get_auth_service),\n):\n    try:\n        return await auth.refresh_access_token(s3_client, refresh_token)\n    except S3AuthError:\n        raise HTTPException(401, \"Invalid refresh token\")\n\n@router.post(\"/logout\")\nasync def logout(\n    refresh_token: str,\n    s3_client = Depends(get_s3_client),\n    auth: S3AuthService = Depends(get_auth_service),\n):\n    await auth.revoke_refresh_token(s3_client, refresh_token)\n    return {\"message\": \"Logged out\"}\n</code></pre>"},{"location":"guide-auth.html#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Use strong secret keys - At least 32 characters, randomly generated</li> <li>Short access token expiry - 15-30 minutes</li> <li>Rotate refresh tokens - New refresh token on each use</li> <li>Rate limit auth endpoints - Prevent brute force</li> <li>Use HTTPS - Always in production</li> <li>Validate passwords - Enforce complexity requirements</li> <li>Clean up tokens - Run periodic cleanup jobs</li> </ol>"},{"location":"guide-caching.html","title":"Caching Guide","text":"<p>Speed up your S3verless application with in-memory caching.</p>"},{"location":"guide-caching.html#overview","title":"Overview","text":"<p>S3verless provides caching backends to reduce S3 API calls and improve response times. Since S3 operations have latency, caching frequently accessed data can significantly improve performance.</p>"},{"location":"guide-caching.html#cache-backends","title":"Cache Backends","text":""},{"location":"guide-caching.html#inmemorycache","title":"InMemoryCache","text":"<p>Simple cache with TTL and optional size limits:</p> <pre><code>from s3verless.cache.memory import InMemoryCache\n\ncache = InMemoryCache(\n    default_ttl=300,      # 5 minutes default TTL\n    max_size=1000,        # Max entries (None for unlimited)\n    cleanup_interval=60,  # Clean expired entries every 60s\n)\n</code></pre>"},{"location":"guide-caching.html#lrucache","title":"LRUCache","text":"<p>Least Recently Used eviction with hit rate tracking:</p> <pre><code>from s3verless.cache.memory import LRUCache\n\ncache = LRUCache(\n    max_size=1000,        # Max entries\n    default_ttl=300,      # 5 minutes default TTL\n)\n\n# Check hit rate\nstats = cache.stats()\nprint(f\"Hit rate: {stats['hit_rate']:.2%}\")\n</code></pre>"},{"location":"guide-caching.html#compositecache","title":"CompositeCache","text":"<p>Multi-tier caching for optimal performance:</p> <pre><code>from s3verless.cache.composite import CompositeCache\n\ncache = CompositeCache([\n    LRUCache(max_size=100, default_ttl=60),     # L1: Fast, small\n    InMemoryCache(max_size=1000, default_ttl=300),  # L2: Larger\n])\n</code></pre> <p>On cache miss, later tiers are checked and hits are promoted to earlier tiers.</p>"},{"location":"guide-caching.html#basic-usage","title":"Basic Usage","text":"<pre><code># Set a value\nawait cache.set(\"product:123\", product_data, ttl=300)\n\n# Get a value\ndata = await cache.get(\"product:123\")\nif data is None:\n    # Cache miss - fetch from S3\n    data = await fetch_from_s3()\n    await cache.set(\"product:123\", data)\n\n# Check existence\nexists = await cache.exists(\"product:123\")\n\n# Delete a value\nawait cache.delete(\"product:123\")\n\n# Delete by pattern\nawait cache.delete_pattern(\"product:*\")\n\n# Clear all\nawait cache.clear()\n</code></pre>"},{"location":"guide-caching.html#cache-key-builder","title":"Cache Key Builder","text":"<p>Generate consistent cache keys:</p> <pre><code>from s3verless.cache.keys import CacheKeyBuilder\n\nkeys = CacheKeyBuilder(prefix=\"myapp\")\n\n# Model instance key\nkey = keys.model_key(Product, \"abc123\")\n# \"myapp:model:Product:abc123\"\n\n# List query key\nkey = keys.model_list_key(\n    Product,\n    filters={\"category\": \"electronics\"},\n    sort_field=\"price\",\n    page=1,\n)\n# \"myapp:list:Product:a1b2c3d4...\"  (hash of query params)\n\n# Count query key\nkey = keys.model_count_key(Product, filters={\"active\": True})\n# \"myapp:count:Product:e5f6g7h8...\"\n\n# Pattern for invalidation\npattern = keys.model_pattern(Product)\n# \"myapp:*:Product:*\"\n</code></pre>"},{"location":"guide-caching.html#caching-patterns","title":"Caching Patterns","text":""},{"location":"guide-caching.html#cache-aside-pattern","title":"Cache-Aside Pattern","text":"<pre><code>async def get_product(product_id: str) -&gt; Product:\n    cache_key = f\"product:{product_id}\"\n\n    # Try cache first\n    cached = await cache.get(cache_key)\n    if cached:\n        return Product(**cached)\n\n    # Fetch from S3\n    product = await product_service.get(s3_client, UUID(product_id))\n    if product:\n        await cache.set(cache_key, product.model_dump(), ttl=300)\n\n    return product\n</code></pre>"},{"location":"guide-caching.html#write-through-pattern","title":"Write-Through Pattern","text":"<pre><code>async def update_product(product_id: str, data: dict) -&gt; Product:\n    # Update in S3\n    product = await product_service.update(s3_client, UUID(product_id), data)\n\n    # Update cache\n    cache_key = f\"product:{product_id}\"\n    await cache.set(cache_key, product.model_dump(), ttl=300)\n\n    # Invalidate list caches\n    await cache.delete_pattern(\"product:list:*\")\n\n    return product\n</code></pre>"},{"location":"guide-caching.html#cache-invalidation","title":"Cache Invalidation","text":"<pre><code>async def invalidate_product_cache(product_id: str):\n    # Delete specific product\n    await cache.delete(f\"product:{product_id}\")\n\n    # Delete all list/count caches for Product\n    await cache.delete_pattern(\"product:list:*\")\n    await cache.delete_pattern(\"product:count:*\")\n</code></pre>"},{"location":"guide-caching.html#integration-with-query","title":"Integration with Query","text":"<pre><code>from s3verless.cache.keys import CacheKeyBuilder\n\nkeys = CacheKeyBuilder()\n\nasync def cached_query(\n    filters: dict = None,\n    page: int = 1,\n    page_size: int = 20,\n) -&gt; dict:\n    cache_key = keys.model_list_key(\n        Product, filters=filters, page=page, page_size=page_size\n    )\n\n    cached = await cache.get(cache_key)\n    if cached:\n        return cached\n\n    query = Query(Product, s3_client, bucket)\n    if filters:\n        query = query.filter(**filters)\n\n    result = await query.paginate(page, page_size)\n\n    # Cache the result\n    result_dict = {\n        \"items\": [item.model_dump() for item in result.items],\n        \"total_count\": result.total_count,\n        \"page\": result.page,\n        \"has_next\": result.has_next,\n    }\n    await cache.set(cache_key, result_dict, ttl=60)\n\n    return result_dict\n</code></pre>"},{"location":"guide-caching.html#fastapi-middleware","title":"FastAPI Middleware","text":"<pre><code>from fastapi import Request\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nclass CacheMiddleware(BaseHTTPMiddleware):\n    def __init__(self, app, cache: CacheBackend):\n        super().__init__(app)\n        self.cache = cache\n\n    async def dispatch(self, request: Request, call_next):\n        # Only cache GET requests\n        if request.method != \"GET\":\n            return await call_next(request)\n\n        # Generate cache key from URL\n        cache_key = f\"response:{request.url.path}:{request.url.query}\"\n\n        # Check cache\n        cached = await self.cache.get(cache_key)\n        if cached:\n            return JSONResponse(cached)\n\n        # Get response\n        response = await call_next(request)\n\n        # Cache successful responses\n        if response.status_code == 200:\n            body = b\"\"\n            async for chunk in response.body_iterator:\n                body += chunk\n            data = json.loads(body)\n            await self.cache.set(cache_key, data, ttl=60)\n            return JSONResponse(data)\n\n        return response\n</code></pre>"},{"location":"guide-caching.html#cache-statistics","title":"Cache Statistics","text":"<pre><code># InMemoryCache stats\nstats = cache.stats()\n# {\"size\": 150, \"max_size\": 1000, \"default_ttl\": 300}\n\n# LRUCache stats with hit rate\nstats = cache.stats()\n# {\"size\": 150, \"max_size\": 1000, \"hits\": 1000, \"misses\": 200, \"hit_rate\": 0.83}\n\n# CompositeCache stats\nstats = cache.stats()\n# {\"tiers\": [{\"type\": \"LRUCache\", ...}, {\"type\": \"InMemoryCache\", ...}]}\n</code></pre>"},{"location":"guide-caching.html#best-practices","title":"Best Practices","text":"<ol> <li>Set appropriate TTLs - Balance freshness vs. performance</li> <li>Invalidate on writes - Keep cache consistent with S3</li> <li>Use patterns for bulk invalidation - When data relationships exist</li> <li>Monitor hit rates - Adjust cache size/TTL based on metrics</li> <li>Size limits - Prevent memory exhaustion with max_size</li> <li>Tiered caching - Small fast L1, larger L2 for different access patterns</li> <li>Cache serializable data - Use model_dump() for Pydantic models</li> </ol>"},{"location":"guide-caching.html#when-to-cache","title":"When to Cache","text":"<p>Good candidates: - Frequently accessed read data - Expensive queries (filters, sorts, aggregations) - Reference data (categories, configurations) - User session data</p> <p>Avoid caching: - Write-heavy data - Large objects - Sensitive data without encryption - Data that must be real-time</p>"},{"location":"guide-deployment.html","title":"Deployment Guide","text":"<p>Deploy S3verless applications to AWS Lambda, Docker, or with LocalStack for development.</p>"},{"location":"guide-deployment.html#aws-lambda-with-mangum","title":"AWS Lambda with Mangum","text":""},{"location":"guide-deployment.html#setup","title":"Setup","text":"<p>Install dependencies:</p> <pre><code>pip install mangum\n</code></pre>"},{"location":"guide-deployment.html#lambda-handler","title":"Lambda Handler","text":"<pre><code># main.py\nfrom mangum import Mangum\nfrom s3verless.fastapi.app import S3verless\nfrom s3verless.core.settings import S3verlessSettings\n\nsettings = S3verlessSettings()\n\napp_builder = S3verless(\n    settings=settings,\n    title=\"My API\",\n    model_packages=[\"models\"],\n)\n\napp = app_builder.create_app()\nhandler = Mangum(app)\n</code></pre>"},{"location":"guide-deployment.html#serverless-framework","title":"Serverless Framework","text":"<pre><code># serverless.yml\nservice: my-s3verless-api\n\nprovider:\n  name: aws\n  runtime: python3.12\n  region: us-east-1\n  iam:\n    role:\n      statements:\n        - Effect: Allow\n          Action:\n            - s3:GetObject\n            - s3:PutObject\n            - s3:DeleteObject\n            - s3:ListBucket\n            - s3:HeadBucket\n            - s3:CreateBucket\n          Resource:\n            - arn:aws:s3:::${self:custom.bucketName}\n            - arn:aws:s3:::${self:custom.bucketName}/*\n\n  environment:\n    AWS_BUCKET_NAME: ${self:custom.bucketName}\n    SECRET_KEY: ${ssm:/my-api/secret-key}\n\ncustom:\n  bucketName: my-s3verless-data-${self:provider.stage}\n\nfunctions:\n  api:\n    handler: main.handler\n    events:\n      - http:\n          path: /{proxy+}\n          method: ANY\n      - http:\n          path: /\n          method: ANY\n\nresources:\n  Resources:\n    DataBucket:\n      Type: AWS::S3::Bucket\n      Properties:\n        BucketName: ${self:custom.bucketName}\n</code></pre> <p>Deploy:</p> <pre><code>serverless deploy\n</code></pre>"},{"location":"guide-deployment.html#sam-template","title":"SAM Template","text":"<pre><code># template.yaml\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nGlobals:\n  Function:\n    Timeout: 30\n    MemorySize: 256\n\nParameters:\n  SecretKey:\n    Type: String\n    NoEcho: true\n\nResources:\n  DataBucket:\n    Type: AWS::S3::Bucket\n\n  ApiFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: main.handler\n      Runtime: python3.12\n      CodeUri: .\n      Environment:\n        Variables:\n          AWS_BUCKET_NAME: !Ref DataBucket\n          SECRET_KEY: !Ref SecretKey\n      Policies:\n        - S3CrudPolicy:\n            BucketName: !Ref DataBucket\n      Events:\n        Api:\n          Type: Api\n          Properties:\n            Path: /{proxy+}\n            Method: ANY\n\nOutputs:\n  ApiUrl:\n    Value: !Sub https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/\n</code></pre> <p>Deploy:</p> <pre><code>sam build\nsam deploy --guided\n</code></pre>"},{"location":"guide-deployment.html#docker","title":"Docker","text":""},{"location":"guide-deployment.html#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.12-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8000\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"guide-deployment.html#docker-composeyml","title":"docker-compose.yml","text":"<pre><code>version: '3.8'\n\nservices:\n  api:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}\n      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}\n      - AWS_REGION=us-east-1\n      - AWS_BUCKET_NAME=${AWS_BUCKET_NAME}\n      - SECRET_KEY=${SECRET_KEY}\n    depends_on:\n      - localstack\n\n  localstack:\n    image: localstack/localstack\n    ports:\n      - \"4566:4566\"\n    environment:\n      - SERVICES=s3\n      - DEBUG=1\n</code></pre>"},{"location":"guide-deployment.html#production-docker","title":"Production Docker","text":"<pre><code>FROM python:3.12-slim as builder\n\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nFROM python:3.12-slim\n\nWORKDIR /app\n\nCOPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages\nCOPY . .\n\nRUN useradd -m appuser\nUSER appuser\n\nEXPOSE 8000\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--workers\", \"4\"]\n</code></pre>"},{"location":"guide-deployment.html#localstack-for-development","title":"LocalStack for Development","text":""},{"location":"guide-deployment.html#setup_1","title":"Setup","text":"<pre><code>docker run -d -p 4566:4566 localstack/localstack\n</code></pre>"},{"location":"guide-deployment.html#configuration","title":"Configuration","text":"<pre><code># .env.local\nAWS_ENDPOINT_URL=http://localhost:4566\nAWS_ACCESS_KEY_ID=test\nAWS_SECRET_ACCESS_KEY=test\nAWS_BUCKET_NAME=local-bucket\nAWS_REGION=us-east-1\n</code></pre>"},{"location":"guide-deployment.html#initialize-bucket","title":"Initialize Bucket","text":"<pre><code># scripts/init_localstack.py\nimport asyncio\nimport aiobotocore.session\n\nasync def init():\n    session = aiobotocore.session.get_session()\n    async with session.create_client(\n        's3',\n        endpoint_url='http://localhost:4566',\n        aws_access_key_id='test',\n        aws_secret_access_key='test',\n        region_name='us-east-1',\n    ) as s3:\n        try:\n            await s3.create_bucket(Bucket='local-bucket')\n            print(\"Bucket created\")\n        except Exception as e:\n            print(f\"Bucket exists or error: {e}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(init())\n</code></pre>"},{"location":"guide-deployment.html#environment-configuration","title":"Environment Configuration","text":""},{"location":"guide-deployment.html#production-checklist","title":"Production Checklist","text":"<pre><code># Required\nAWS_BUCKET_NAME=prod-data-bucket\nSECRET_KEY=$(openssl rand -hex 32)  # Generate secure key\n\n# AWS (if not using IAM roles)\nAWS_ACCESS_KEY_ID=...\nAWS_SECRET_ACCESS_KEY=...\nAWS_REGION=us-east-1\n\n# Optional\nS3_BASE_PATH=data/\nACCESS_TOKEN_EXPIRE_MINUTES=15\nREFRESH_TOKEN_EXPIRE_DAYS=7\n\n# Admin (optional)\nCREATE_DEFAULT_ADMIN=true\nDEFAULT_ADMIN_USERNAME=admin\nDEFAULT_ADMIN_PASSWORD=...  # Use secrets manager\nDEFAULT_ADMIN_EMAIL=admin@example.com\n</code></pre>"},{"location":"guide-deployment.html#aws-secrets-manager","title":"AWS Secrets Manager","text":"<pre><code>import boto3\nimport json\n\ndef get_secrets():\n    client = boto3.client('secretsmanager')\n    response = client.get_secret_value(SecretId='my-api/secrets')\n    return json.loads(response['SecretString'])\n\n# In settings\nsecrets = get_secrets()\nsettings = S3verlessSettings(\n    secret_key=secrets['SECRET_KEY'],\n    # ...\n)\n</code></pre>"},{"location":"guide-deployment.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"guide-deployment.html#lambda-cold-starts","title":"Lambda Cold Starts","text":"<pre><code># Keep connections warm\nfrom s3verless.core.client import S3ClientManager\n\n# Initialize outside handler\nmanager = S3ClientManager(settings)\n\ndef handler(event, context):\n    # Manager is reused across invocations\n    pass\n</code></pre>"},{"location":"guide-deployment.html#memory-settings","title":"Memory Settings","text":"<ul> <li>Lambda: Start with 256MB, increase if needed</li> <li>Docker: Set memory limits based on expected load</li> <li>Monitor with CloudWatch/Prometheus</li> </ul>"},{"location":"guide-deployment.html#connection-pooling","title":"Connection Pooling","text":"<pre><code>from s3verless.core.client import PoolConfig\n\npool_config = PoolConfig(\n    max_connections=10,\n    connection_timeout=5.0,\n)\nmanager = S3ClientManager(settings, pool_config)\n</code></pre>"},{"location":"guide-deployment.html#monitoring","title":"Monitoring","text":""},{"location":"guide-deployment.html#cloudwatch-logs","title":"CloudWatch Logs","text":"<p>Lambda logs automatically to CloudWatch. Add structured logging:</p> <pre><code>import logging\nimport json\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ndef log_request(event):\n    logger.info(json.dumps({\n        \"type\": \"request\",\n        \"path\": event.get(\"path\"),\n        \"method\": event.get(\"httpMethod\"),\n    }))\n</code></pre>"},{"location":"guide-deployment.html#health-check","title":"Health Check","text":"<pre><code>@app.get(\"/health\")\nasync def health():\n    try:\n        async with s3_manager.get_async_client() as s3:\n            await s3.head_bucket(Bucket=bucket_name)\n        return {\"status\": \"healthy\", \"s3\": \"connected\"}\n    except Exception as e:\n        return {\"status\": \"unhealthy\", \"error\": str(e)}\n</code></pre>"},{"location":"guide-deployment.html#security","title":"Security","text":""},{"location":"guide-deployment.html#iam-policy-least-privilege","title":"IAM Policy (Least Privilege)","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:PutObject\",\n        \"s3:DeleteObject\"\n      ],\n      \"Resource\": \"arn:aws:s3:::my-bucket/data/*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:ListBucket\"],\n      \"Resource\": \"arn:aws:s3:::my-bucket\",\n      \"Condition\": {\n        \"StringLike\": {\"s3:prefix\": [\"data/*\"]}\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"guide-deployment.html#s3-bucket-policy","title":"S3 Bucket Policy","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenyUnencryptedUploads\",\n      \"Effect\": \"Deny\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:PutObject\",\n      \"Resource\": \"arn:aws:s3:::my-bucket/*\",\n      \"Condition\": {\n        \"StringNotEquals\": {\n          \"s3:x-amz-server-side-encryption\": \"AES256\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"guide-deployment.html#enable-encryption","title":"Enable Encryption","text":"<pre><code># S3 bucket encryption (set via AWS Console or CloudFormation)\n# Or encrypt in application:\nawait s3_client.put_object(\n    Bucket=bucket,\n    Key=key,\n    Body=data,\n    ServerSideEncryption='AES256',\n)\n</code></pre>"},{"location":"guide-deployment.html#cicd","title":"CI/CD","text":""},{"location":"guide-deployment.html#github-actions","title":"GitHub Actions","text":"<pre><code>name: Deploy\n\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n\n      - name: Run tests\n        run: pytest\n\n      - name: Deploy to Lambda\n        uses: serverless/github-action@v3\n        with:\n          args: deploy\n        env:\n          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n</code></pre>"},{"location":"guide-getting-started.html","title":"Getting Started with S3verless","text":"<p>Build serverless APIs using S3 as your database in minutes.</p>"},{"location":"guide-getting-started.html#installation","title":"Installation","text":"<pre><code>pip install s3verless\n</code></pre>"},{"location":"guide-getting-started.html#quick-start","title":"Quick Start","text":""},{"location":"guide-getting-started.html#1-define-a-model","title":"1. Define a Model","text":"<pre><code># models.py\nfrom s3verless.core.base import BaseS3Model\n\nclass Task(BaseS3Model):\n    _plural_name = \"tasks\"\n\n    title: str\n    completed: bool = False\n    priority: int = 0\n</code></pre>"},{"location":"guide-getting-started.html#2-create-the-application","title":"2. Create the Application","text":"<pre><code># main.py\nfrom s3verless.fastapi.app import S3verless\nfrom s3verless.core.settings import S3verlessSettings\n\nsettings = S3verlessSettings(\n    aws_bucket_name=\"my-app-bucket\",\n    aws_region=\"us-east-1\",\n)\n\napp_builder = S3verless(\n    settings=settings,\n    title=\"Task API\",\n    model_packages=[\"models\"],\n)\n\napp = app_builder.create_app()\n</code></pre>"},{"location":"guide-getting-started.html#3-run-the-api","title":"3. Run the API","text":"<pre><code>uvicorn main:app --reload\n</code></pre> <p>Your API is now available at <code>http://localhost:8000</code> with: - <code>GET /tasks</code> - List all tasks - <code>POST /tasks</code> - Create a task - <code>GET /tasks/{id}</code> - Get a task - <code>PUT /tasks/{id}</code> - Update a task - <code>DELETE /tasks/{id}</code> - Delete a task - <code>GET /admin</code> - Admin interface</p>"},{"location":"guide-getting-started.html#local-development-with-localstack","title":"Local Development with LocalStack","text":"<p>For local development without AWS costs:</p> <pre><code># Start LocalStack\ndocker run -d -p 4566:4566 localstack/localstack\n\n# Configure S3verless\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_BUCKET_NAME=local-bucket\n</code></pre>"},{"location":"guide-getting-started.html#configuration","title":"Configuration","text":"<p>S3verless uses environment variables or direct settings:</p> <pre><code>settings = S3verlessSettings(\n    # Required\n    aws_bucket_name=\"my-bucket\",\n\n    # AWS credentials (or use IAM roles)\n    aws_access_key_id=\"...\",\n    aws_secret_access_key=\"...\",\n    aws_region=\"us-east-1\",\n\n    # LocalStack/MinIO\n    aws_endpoint_url=\"http://localhost:4566\",\n\n    # Auth settings\n    secret_key=\"your-secret-key\",\n    access_token_expire_minutes=30,\n\n    # Admin user\n    create_default_admin=True,\n    default_admin_username=\"admin\",\n    default_admin_password=\"changeme\",\n    default_admin_email=\"admin@example.com\",\n)\n</code></pre>"},{"location":"guide-getting-started.html#environment-variables","title":"Environment Variables","text":"<pre><code># AWS Configuration\nAWS_BUCKET_NAME=my-bucket\nAWS_REGION=us-east-1\nAWS_ACCESS_KEY_ID=...\nAWS_SECRET_ACCESS_KEY=...\nAWS_ENDPOINT_URL=http://localhost:4566  # For LocalStack\n\n# Auth\nSECRET_KEY=your-secret-key\nALGORITHM=HS256\nACCESS_TOKEN_EXPIRE_MINUTES=30\n\n# Data\nS3_BASE_PATH=data/\n\n# Admin\nCREATE_DEFAULT_ADMIN=true\nDEFAULT_ADMIN_USERNAME=admin\nDEFAULT_ADMIN_PASSWORD=changeme\nDEFAULT_ADMIN_EMAIL=admin@example.com\n</code></pre>"},{"location":"guide-getting-started.html#project-structure","title":"Project Structure","text":"<p>Recommended project layout:</p> <pre><code>myapp/\n\u251c\u2500\u2500 main.py           # FastAPI app\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 task.py       # Task model\n\u2502   \u2514\u2500\u2500 user.py       # Custom user fields\n\u251c\u2500\u2500 routers/\n\u2502   \u2514\u2500\u2500 custom.py     # Custom endpoints\n\u251c\u2500\u2500 seeds/\n\u2502   \u2514\u2500\u2500 tasks.json    # Seed data\n\u2514\u2500\u2500 migrations/\n    \u2514\u2500\u2500 0001_add_priority.py\n</code></pre>"},{"location":"guide-getting-started.html#next-steps","title":"Next Steps","text":"<ul> <li>Models Guide - Define models with indexes and validation</li> <li>Queries Guide - Filter, sort, and paginate data</li> <li>Auth Guide - Add authentication and authorization</li> <li>Deployment Guide - Deploy to AWS Lambda</li> </ul>"},{"location":"guide-migrations.html","title":"Migrations Guide","text":"<p>Evolve your data schema without losing existing data.</p>"},{"location":"guide-migrations.html#overview","title":"Overview","text":"<p>S3verless migrations transform existing JSON objects in S3 when your model schema changes. Unlike SQL migrations, they modify each object's data directly.</p>"},{"location":"guide-migrations.html#creating-migrations","title":"Creating Migrations","text":""},{"location":"guide-migrations.html#basic-migration","title":"Basic Migration","text":"<pre><code># migrations/0001_add_status_field.py\nfrom s3verless.migrations.base import Migration\n\nmigration = Migration(\n    version=\"0001\",\n    model_name=\"Product\",\n    description=\"Add status field with default 'active'\",\n    apply=lambda data: {**data, \"status\": \"active\"},\n    rollback=lambda data: {k: v for k, v in data.items() if k != \"status\"},\n    reversible=True,\n)\n</code></pre>"},{"location":"guide-migrations.html#migration-with-logic","title":"Migration with Logic","text":"<pre><code># migrations/0002_split_name.py\nfrom s3verless.migrations.base import Migration\n\ndef apply_split_name(data):\n    \"\"\"Split 'name' into 'first_name' and 'last_name'.\"\"\"\n    if \"name\" in data and \"first_name\" not in data:\n        parts = data[\"name\"].split(\" \", 1)\n        return {\n            **{k: v for k, v in data.items() if k != \"name\"},\n            \"first_name\": parts[0],\n            \"last_name\": parts[1] if len(parts) &gt; 1 else \"\",\n        }\n    return data\n\ndef rollback_split_name(data):\n    \"\"\"Merge 'first_name' and 'last_name' back to 'name'.\"\"\"\n    if \"first_name\" in data:\n        name = data.get(\"first_name\", \"\")\n        if data.get(\"last_name\"):\n            name += \" \" + data[\"last_name\"]\n        return {\n            **{k: v for k, v in data.items() if k not in (\"first_name\", \"last_name\")},\n            \"name\": name,\n        }\n    return data\n\nmigration = Migration(\n    version=\"0002\",\n    model_name=\"User\",\n    description=\"Split name into first_name and last_name\",\n    apply=apply_split_name,\n    rollback=rollback_split_name,\n    reversible=True,\n)\n</code></pre>"},{"location":"guide-migrations.html#running-migrations","title":"Running Migrations","text":""},{"location":"guide-migrations.html#using-migrationrunner","title":"Using MigrationRunner","text":"<pre><code>from pathlib import Path\nfrom s3verless.migrations.runner import MigrationRunner\n\nrunner = MigrationRunner(\n    s3_client,\n    bucket_name=\"my-bucket\",\n    migrations_dir=Path(\"./migrations\"),\n)\n\n# Run all pending migrations\nresults = await runner.run_pending()\nfor result in results:\n    print(f\"{result['version']}: {result['status']} - {result['objects_transformed']} objects\")\n</code></pre>"},{"location":"guide-migrations.html#programmatic-registration","title":"Programmatic Registration","text":"<pre><code>runner = MigrationRunner(s3_client, bucket_name)\nrunner.register(migration)\nawait runner.run_pending()\n</code></pre>"},{"location":"guide-migrations.html#check-applied-migrations","title":"Check Applied Migrations","text":"<pre><code>applied = await runner.get_applied_migrations()\nprint(f\"Applied: {applied}\")  # [\"0001\", \"0002\"]\n\npending = runner.get_pending_migrations()\nprint(f\"Pending: {[m.version for m in pending]}\")\n</code></pre>"},{"location":"guide-migrations.html#rollback","title":"Rollback","text":"<pre><code># Rollback a specific migration\nresult = await runner.rollback(\"0002\")\nprint(f\"Rolled back {result['objects_transformed']} objects\")\n</code></pre> <p>Only migrations marked <code>reversible=True</code> can be rolled back.</p>"},{"location":"guide-migrations.html#migration-patterns","title":"Migration Patterns","text":""},{"location":"guide-migrations.html#adding-a-field","title":"Adding a Field","text":"<pre><code>Migration(\n    version=\"0001\",\n    model_name=\"Product\",\n    description=\"Add rating field\",\n    apply=lambda data: {**data, \"rating\": 0.0},\n    rollback=lambda data: {k: v for k, v in data.items() if k != \"rating\"},\n    reversible=True,\n)\n</code></pre>"},{"location":"guide-migrations.html#removing-a-field","title":"Removing a Field","text":"<pre><code>Migration(\n    version=\"0002\",\n    model_name=\"Product\",\n    description=\"Remove deprecated field\",\n    apply=lambda data: {k: v for k, v in data.items() if k != \"old_field\"},\n    rollback=lambda data: {**data, \"old_field\": None},  # Can't restore data\n    reversible=False,  # Mark as irreversible\n)\n</code></pre>"},{"location":"guide-migrations.html#renaming-a-field","title":"Renaming a Field","text":"<pre><code>def rename_field(data):\n    if \"old_name\" in data:\n        return {\n            **{k: v for k, v in data.items() if k != \"old_name\"},\n            \"new_name\": data[\"old_name\"],\n        }\n    return data\n\ndef unrename_field(data):\n    if \"new_name\" in data:\n        return {\n            **{k: v for k, v in data.items() if k != \"new_name\"},\n            \"old_name\": data[\"new_name\"],\n        }\n    return data\n\nMigration(\n    version=\"0003\",\n    model_name=\"Product\",\n    description=\"Rename old_name to new_name\",\n    apply=rename_field,\n    rollback=unrename_field,\n    reversible=True,\n)\n</code></pre>"},{"location":"guide-migrations.html#converting-data-types","title":"Converting Data Types","text":"<pre><code>def convert_price_to_cents(data):\n    if \"price\" in data and isinstance(data[\"price\"], float):\n        return {**data, \"price\": int(data[\"price\"] * 100)}\n    return data\n\ndef convert_price_to_dollars(data):\n    if \"price\" in data and isinstance(data[\"price\"], int):\n        return {**data, \"price\": data[\"price\"] / 100}\n    return data\n\nMigration(\n    version=\"0004\",\n    model_name=\"Product\",\n    description=\"Convert price from dollars to cents\",\n    apply=convert_price_to_cents,\n    rollback=convert_price_to_dollars,\n    reversible=True,\n)\n</code></pre>"},{"location":"guide-migrations.html#restructuring-data","title":"Restructuring Data","text":"<pre><code>def flatten_address(data):\n    if \"address\" in data and isinstance(data[\"address\"], dict):\n        addr = data[\"address\"]\n        return {\n            **{k: v for k, v in data.items() if k != \"address\"},\n            \"street\": addr.get(\"street\", \"\"),\n            \"city\": addr.get(\"city\", \"\"),\n            \"zip\": addr.get(\"zip\", \"\"),\n        }\n    return data\n\nMigration(\n    version=\"0005\",\n    model_name=\"User\",\n    description=\"Flatten nested address object\",\n    apply=flatten_address,\n    reversible=False,  # Hard to reverse reliably\n)\n</code></pre>"},{"location":"guide-migrations.html#migration-history","title":"Migration History","text":"<p>Migrations are tracked in <code>_system/migration_history.json</code>:</p> <pre><code>{\n  \"records\": [\n    {\n      \"version\": \"0001\",\n      \"model_name\": \"Product\",\n      \"description\": \"Add status field\",\n      \"applied_at\": \"2024-01-15T10:30:00Z\",\n      \"objects_transformed\": 150\n    }\n  ]\n}\n</code></pre>"},{"location":"guide-migrations.html#best-practices","title":"Best Practices","text":"<ol> <li>Version sequentially - Use <code>0001</code>, <code>0002</code>, etc.</li> <li>One change per migration - Easier to rollback</li> <li>Test migrations - Run on copy of data first</li> <li>Make reversible when possible - But mark irreversible if data loss occurs</li> <li>Handle missing fields - Check if field exists before transforming</li> <li>Document changes - Clear descriptions help future you</li> <li>Backup before running - S3 versioning or manual backup</li> </ol>"},{"location":"guide-migrations.html#cli-integration","title":"CLI Integration","text":"<p>You can create a CLI command for migrations:</p> <pre><code>import asyncio\nfrom pathlib import Path\n\nasync def run_migrations():\n    runner = MigrationRunner(s3_client, bucket_name, Path(\"./migrations\"))\n    results = await runner.run_pending()\n    for r in results:\n        print(f\"{r['version']}: {r['status']}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(run_migrations())\n</code></pre>"},{"location":"guide-models.html","title":"Models Guide","text":"<p>Define data models with validation, indexes, and unique constraints.</p>"},{"location":"guide-models.html#basic-model","title":"Basic Model","text":"<p>All models inherit from <code>BaseS3Model</code>:</p> <pre><code>from s3verless.core.base import BaseS3Model\n\nclass Product(BaseS3Model):\n    name: str\n    price: float\n    description: str | None = None\n</code></pre> <p>Every model automatically gets: - <code>id: UUID</code> - Unique identifier - <code>created_at: datetime</code> - Creation timestamp - <code>updated_at: datetime</code> - Last modification</p>"},{"location":"guide-models.html#class-configuration","title":"Class Configuration","text":""},{"location":"guide-models.html#plural-name","title":"Plural Name","text":"<p>Controls the API route and S3 prefix:</p> <pre><code>class Product(BaseS3Model):\n    _plural_name = \"products\"  # API: /products, S3: data/products/\n</code></pre> <p>Default: lowercase class name.</p>"},{"location":"guide-models.html#unique-fields","title":"Unique Fields","text":"<p>Enforce uniqueness across all instances:</p> <pre><code>class User(BaseS3Model):\n    _unique_fields = [\"username\", \"email\"]\n\n    username: str\n    email: str\n</code></pre> <p>Unique validation runs on create and update.</p>"},{"location":"guide-models.html#indexed-fields","title":"Indexed Fields","text":"<p>Mark fields for optimized queries:</p> <pre><code>class Product(BaseS3Model):\n    _indexed_fields = [\"category\", \"status\"]\n\n    category: str\n    status: str\n</code></pre>"},{"location":"guide-models.html#disable-auto-api","title":"Disable Auto API","text":"<p>Exclude model from auto-generated routes:</p> <pre><code>class InternalLog(BaseS3Model):\n    _enable_api = False\n\n    message: str\n    level: str\n</code></pre>"},{"location":"guide-models.html#field-types","title":"Field Types","text":"<p>Use standard Python types with Pydantic validation:</p> <pre><code>from datetime import datetime\nfrom decimal import Decimal\nfrom enum import Enum\nfrom uuid import UUID\n\nclass Status(str, Enum):\n    DRAFT = \"draft\"\n    PUBLISHED = \"published\"\n\nclass Article(BaseS3Model):\n    title: str                          # Required string\n    content: str | None = None          # Optional string\n    views: int = 0                       # Integer with default\n    price: Decimal                       # Exact decimal\n    rating: float                        # Floating point\n    is_featured: bool = False            # Boolean\n    tags: list[str] = []                # List of strings\n    metadata: dict = {}                  # Dictionary\n    status: Status = Status.DRAFT        # Enum\n    author_id: UUID                      # UUID reference\n    published_at: datetime | None = None # Optional datetime\n</code></pre>"},{"location":"guide-models.html#validation","title":"Validation","text":"<p>Use Pydantic validators:</p> <pre><code>from pydantic import field_validator, EmailStr\n\nclass User(BaseS3Model):\n    email: EmailStr  # Built-in email validation\n    age: int\n\n    @field_validator(\"age\")\n    @classmethod\n    def validate_age(cls, v):\n        if v &lt; 0 or v &gt; 150:\n            raise ValueError(\"Age must be between 0 and 150\")\n        return v\n</code></pre>"},{"location":"guide-models.html#computed-properties","title":"Computed Properties","text":"<p>Add read-only computed fields:</p> <pre><code>class Order(BaseS3Model):\n    items: list[dict]\n    tax_rate: float = 0.1\n\n    @property\n    def subtotal(self) -&gt; float:\n        return sum(item[\"price\"] * item[\"quantity\"] for item in self.items)\n\n    @property\n    def total(self) -&gt; float:\n        return self.subtotal * (1 + self.tax_rate)\n</code></pre>"},{"location":"guide-models.html#model-methods","title":"Model Methods","text":"<p>Add custom methods:</p> <pre><code>class Task(BaseS3Model):\n    title: str\n    completed: bool = False\n    completed_at: datetime | None = None\n\n    def mark_complete(self) -&gt; None:\n        self.completed = True\n        self.completed_at = datetime.now(timezone.utc)\n        self.touch()  # Update updated_at\n</code></pre>"},{"location":"guide-models.html#s3-storage","title":"S3 Storage","text":"<p>Models are stored as JSON in S3:</p> <pre><code>bucket/\n\u2514\u2500\u2500 data/\n    \u2514\u2500\u2500 products/\n        \u251c\u2500\u2500 550e8400-e29b-41d4-a716-446655440000.json\n        \u2514\u2500\u2500 6ba7b810-9dad-11d1-80b4-00c04fd430c8.json\n</code></pre> <p>Each file contains:</p> <pre><code>{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"created_at\": \"2024-01-15T10:30:00Z\",\n  \"updated_at\": \"2024-01-15T10:30:00Z\",\n  \"name\": \"Widget\",\n  \"price\": 29.99\n}\n</code></pre>"},{"location":"guide-models.html#working-with-models","title":"Working with Models","text":""},{"location":"guide-models.html#create","title":"Create","text":"<pre><code>from s3verless.core.service import S3DataService\n\nservice = S3DataService(Product, \"my-bucket\")\n\nproduct = await service.create(s3_client, Product(\n    name=\"Widget\",\n    price=29.99,\n))\n</code></pre>"},{"location":"guide-models.html#read","title":"Read","text":"<pre><code>product = await service.get(s3_client, product.id)\n</code></pre>"},{"location":"guide-models.html#update","title":"Update","text":"<pre><code>product.price = 24.99\nproduct = await service.update(s3_client, product.id, product)\n</code></pre>"},{"location":"guide-models.html#delete","title":"Delete","text":"<pre><code>await service.delete(s3_client, product.id)\n</code></pre>"},{"location":"guide-models.html#list","title":"List","text":"<pre><code>products, next_marker = await service.list_by_prefix(s3_client, limit=100)\n</code></pre>"},{"location":"guide-models.html#best-practices","title":"Best Practices","text":"<ol> <li>Keep models small - S3 reads entire objects, so smaller is faster</li> <li>Use indexed fields - Mark frequently filtered fields</li> <li>Avoid nested objects - Flatten when possible for better query performance</li> <li>Use enums for status - Type safety and validation</li> <li>Add timestamps - Already included, but add custom ones as needed</li> </ol>"},{"location":"guide-queries.html","title":"Queries Guide","text":"<p>Filter, sort, and paginate your S3 data with the fluent Query API.</p>"},{"location":"guide-queries.html#basic-usage","title":"Basic Usage","text":"<pre><code>from s3verless.core.query import Query\n\n# Get all products\nproducts = await Query(Product, s3_client, \"my-bucket\").all()\n\n# Get first product\nproduct = await Query(Product, s3_client, \"my-bucket\").first()\n\n# Count products\ncount = await Query(Product, s3_client, \"my-bucket\").count()\n</code></pre>"},{"location":"guide-queries.html#filtering","title":"Filtering","text":""},{"location":"guide-queries.html#exact-match","title":"Exact Match","text":"<pre><code># Single filter\nproducts = await (\n    Query(Product, s3_client, bucket)\n    .filter(category=\"electronics\")\n    .all()\n)\n\n# Multiple filters (AND)\nproducts = await (\n    Query(Product, s3_client, bucket)\n    .filter(category=\"electronics\", in_stock=True)\n    .all()\n)\n</code></pre>"},{"location":"guide-queries.html#comparison-operators","title":"Comparison Operators","text":"<pre><code># Greater than\nproducts = await Query(Product, s3_client, bucket).filter(price__gt=100).all()\n\n# Less than or equal\nproducts = await Query(Product, s3_client, bucket).filter(price__lte=50).all()\n\n# Not equal\nproducts = await Query(Product, s3_client, bucket).filter(status__ne=\"archived\").all()\n</code></pre> <p>Available operators: - <code>__eq</code> - Equal (default) - <code>__ne</code> - Not equal - <code>__gt</code> - Greater than - <code>__gte</code> - Greater than or equal - <code>__lt</code> - Less than - <code>__lte</code> - Less than or equal</p>"},{"location":"guide-queries.html#list-membership","title":"List Membership","text":"<pre><code># In list\nproducts = await (\n    Query(Product, s3_client, bucket)\n    .filter(category__in=[\"electronics\", \"computers\"])\n    .all()\n)\n\n# Not in list\nproducts = await (\n    Query(Product, s3_client, bucket)\n    .filter(status__nin=[\"archived\", \"deleted\"])\n    .all()\n)\n</code></pre>"},{"location":"guide-queries.html#string-matching","title":"String Matching","text":"<pre><code># Contains (case-sensitive)\nproducts = await Query(Product, s3_client, bucket).filter(name__contains=\"Pro\").all()\n\n# Contains (case-insensitive)\nproducts = await Query(Product, s3_client, bucket).filter(name__icontains=\"pro\").all()\n\n# Starts with\nproducts = await Query(Product, s3_client, bucket).filter(sku__startswith=\"ELEC-\").all()\n\n# Ends with\nproducts = await Query(Product, s3_client, bucket).filter(name__endswith=\"Edition\").all()\n</code></pre>"},{"location":"guide-queries.html#null-checks","title":"Null Checks","text":"<pre><code># Is null\nproducts = await Query(Product, s3_client, bucket).filter(description__isnull=True).all()\n\n# Is not null\nproducts = await Query(Product, s3_client, bucket).filter(description__isnull=False).all()\n</code></pre>"},{"location":"guide-queries.html#exclusion","title":"Exclusion","text":"<p>Use <code>exclude()</code> to negate conditions:</p> <pre><code># Exclude archived products\nproducts = await (\n    Query(Product, s3_client, bucket)\n    .filter(category=\"electronics\")\n    .exclude(status=\"archived\")\n    .all()\n)\n</code></pre>"},{"location":"guide-queries.html#sorting","title":"Sorting","text":"<pre><code># Ascending (default)\nproducts = await Query(Product, s3_client, bucket).order_by(\"price\").all()\n\n# Descending (prefix with -)\nproducts = await Query(Product, s3_client, bucket).order_by(\"-created_at\").all()\n</code></pre>"},{"location":"guide-queries.html#limiting-results","title":"Limiting Results","text":"<pre><code># Limit\nproducts = await Query(Product, s3_client, bucket).limit(10).all()\n\n# Offset\nproducts = await Query(Product, s3_client, bucket).offset(20).limit(10).all()\n</code></pre>"},{"location":"guide-queries.html#pagination","title":"Pagination","text":"<pre><code>from s3verless.core.query import QueryResult\n\nresult: QueryResult = await (\n    Query(Product, s3_client, bucket)\n    .filter(category=\"electronics\")\n    .order_by(\"-price\")\n    .paginate(page=1, page_size=20)\n)\n\nprint(result.items)       # List of products\nprint(result.total_count) # Total matching products\nprint(result.page)        # Current page (1)\nprint(result.page_size)   # Items per page (20)\nprint(result.has_next)    # True if more pages exist\nprint(result.has_prev)    # False for first page\n</code></pre>"},{"location":"guide-queries.html#field-selection","title":"Field Selection","text":"<p>Select specific fields to reduce data transfer:</p> <pre><code>products = await (\n    Query(Product, s3_client, bucket)\n    .select(\"id\", \"name\", \"price\")\n    .all()\n)\n</code></pre>"},{"location":"guide-queries.html#getting-single-results","title":"Getting Single Results","text":"<pre><code># Get first or None\nproduct = await Query(Product, s3_client, bucket).filter(sku=\"ABC123\").first()\n\n# Get exactly one (raises if 0 or &gt;1)\nproduct = await Query(Product, s3_client, bucket).filter(sku=\"ABC123\").get()\n\n# Check existence\nexists = await Query(Product, s3_client, bucket).filter(sku=\"ABC123\").exists()\n</code></pre>"},{"location":"guide-queries.html#chaining","title":"Chaining","text":"<p>All methods return the query for chaining:</p> <pre><code>products = await (\n    Query(Product, s3_client, bucket)\n    .filter(category=\"electronics\")\n    .filter(price__gte=50)\n    .exclude(status=\"archived\")\n    .order_by(\"-rating\")\n    .select(\"id\", \"name\", \"price\", \"rating\")\n    .limit(10)\n    .all()\n)\n</code></pre>"},{"location":"guide-queries.html#performance-tips","title":"Performance Tips","text":"<ol> <li>Use indexed fields - Define <code>_indexed_fields</code> on models</li> <li>Limit results - Always use <code>.limit()</code> or <code>.paginate()</code></li> <li>Select fields - Use <code>.select()</code> if you don't need all fields</li> <li>Filter early - Put most selective filters first</li> </ol>"},{"location":"guide-queries.html#example-search-api","title":"Example: Search API","text":"<pre><code>@app.get(\"/products/search\")\nasync def search_products(\n    q: str | None = None,\n    category: str | None = None,\n    min_price: float | None = None,\n    max_price: float | None = None,\n    sort: str = \"-created_at\",\n    page: int = 1,\n    page_size: int = 20,\n):\n    query = Query(Product, s3_client, bucket)\n\n    if q:\n        query = query.filter(name__icontains=q)\n    if category:\n        query = query.filter(category=category)\n    if min_price:\n        query = query.filter(price__gte=min_price)\n    if max_price:\n        query = query.filter(price__lte=max_price)\n\n    return await query.order_by(sort).paginate(page, page_size)\n</code></pre>"},{"location":"guide-relationships.html","title":"Relationships Guide","text":"<p>Define and work with relationships between S3-stored models.</p>"},{"location":"guide-relationships.html#relationship-types","title":"Relationship Types","text":"<p>S3verless supports: - Many-to-One - Child references parent via foreign key - One-to-Many - Parent has many children - One-to-One - Single related object</p>"},{"location":"guide-relationships.html#defining-relationships","title":"Defining Relationships","text":""},{"location":"guide-relationships.html#foreign-key-many-to-one","title":"Foreign Key (Many-to-One)","text":"<p>A post belongs to an author:</p> <pre><code>from uuid import UUID\nfrom s3verless.core.base import BaseS3Model\nfrom s3verless.core.relationships import foreign_key, OnDelete\n\nclass Author(BaseS3Model):\n    _plural_name = \"authors\"\n    name: str\n    email: str\n\nclass Post(BaseS3Model):\n    _plural_name = \"posts\"\n    title: str\n    content: str\n    author_id: UUID  # Foreign key field\n\n    _relationships = [\n        foreign_key(\"Author\", on_delete=OnDelete.CASCADE)\n    ]\n</code></pre>"},{"location":"guide-relationships.html#has-many-one-to-many","title":"Has Many (One-to-Many)","text":"<p>An author has many posts:</p> <pre><code>from s3verless.core.relationships import has_many, OnDelete\n\nclass Author(BaseS3Model):\n    _plural_name = \"authors\"\n    name: str\n\n    _relationships = [\n        has_many(\"Post\", foreign_key=\"author_id\", on_delete=OnDelete.CASCADE)\n    ]\n</code></pre>"},{"location":"guide-relationships.html#has-one-one-to-one","title":"Has One (One-to-One)","text":"<p>A user has one profile:</p> <pre><code>from s3verless.core.relationships import has_one\n\nclass User(BaseS3Model):\n    _plural_name = \"users\"\n    username: str\n\n    _relationships = [\n        has_one(\"Profile\", foreign_key=\"user_id\")\n    ]\n\nclass Profile(BaseS3Model):\n    _plural_name = \"profiles\"\n    user_id: UUID\n    bio: str\n</code></pre>"},{"location":"guide-relationships.html#on-delete-behavior","title":"On Delete Behavior","text":"<p>Control what happens when a related object is deleted:</p> <pre><code>from s3verless.core.relationships import OnDelete\n\n# CASCADE - Delete related objects\nhas_many(\"Post\", \"author_id\", on_delete=OnDelete.CASCADE)\n\n# SET_NULL - Set foreign key to null\nhas_many(\"Post\", \"author_id\", on_delete=OnDelete.SET_NULL)\n\n# PROTECT - Prevent deletion if related objects exist\nhas_many(\"Post\", \"author_id\", on_delete=OnDelete.PROTECT)\n\n# DO_NOTHING - Leave orphaned references (default)\nhas_many(\"Post\", \"author_id\", on_delete=OnDelete.DO_NOTHING)\n</code></pre>"},{"location":"guide-relationships.html#loading-related-objects","title":"Loading Related Objects","text":""},{"location":"guide-relationships.html#manual-loading","title":"Manual Loading","text":"<pre><code>from s3verless.core.service import S3DataService\n\n# Get post with author\npost_service = S3DataService(Post, bucket)\nauthor_service = S3DataService(Author, bucket)\n\npost = await post_service.get(s3_client, post_id)\nauthor = await author_service.get(s3_client, post.author_id)\n</code></pre>"},{"location":"guide-relationships.html#relationship-resolver","title":"Relationship Resolver","text":"<pre><code>from s3verless.core.relationships import RelationshipResolver\n\nresolver = RelationshipResolver(s3_client, bucket)\n\n# Resolve many-to-one (get authors for posts)\nposts = await Query(Post, s3_client, bucket).all()\nrelationship = Post._relationships[0]  # author relationship\nauthor_map = await resolver.resolve(posts, relationship)\n# {post_id: author_object, ...}\n</code></pre>"},{"location":"guide-relationships.html#cascade-handler","title":"Cascade Handler","text":"<p>Handle cascading deletes:</p> <pre><code>from s3verless.core.relationships import CascadeHandler\n\nhandler = CascadeHandler(s3_client, bucket)\n\n# Before deleting an author\nauthor = await author_service.get(s3_client, author_id)\ntry:\n    results = await handler.handle_delete(author, Author._relationships)\n    # results: {cascaded: n, set_null: n, protected: []}\n    await author_service.delete(s3_client, author_id)\nexcept ValueError as e:\n    # Deletion blocked by PROTECT relationship\n    print(f\"Cannot delete: {e}\")\n</code></pre>"},{"location":"guide-relationships.html#example-blog-with-comments","title":"Example: Blog with Comments","text":"<pre><code>from uuid import UUID\nfrom s3verless.core.base import BaseS3Model\nfrom s3verless.core.relationships import has_many, foreign_key, OnDelete\n\nclass Author(BaseS3Model):\n    _plural_name = \"authors\"\n    name: str\n    bio: str | None = None\n\n    _relationships = [\n        has_many(\"Post\", \"author_id\", on_delete=OnDelete.CASCADE)\n    ]\n\nclass Post(BaseS3Model):\n    _plural_name = \"posts\"\n    title: str\n    content: str\n    author_id: UUID\n    published: bool = False\n\n    _relationships = [\n        foreign_key(\"Author\"),\n        has_many(\"Comment\", \"post_id\", on_delete=OnDelete.CASCADE)\n    ]\n\nclass Comment(BaseS3Model):\n    _plural_name = \"comments\"\n    content: str\n    post_id: UUID\n    commenter_name: str\n\n    _relationships = [\n        foreign_key(\"Post\")\n    ]\n</code></pre>"},{"location":"guide-relationships.html#usage","title":"Usage","text":"<pre><code># Create author and post\nauthor = await author_service.create(s3_client, Author(name=\"Jane\"))\npost = await post_service.create(s3_client, Post(\n    title=\"Hello World\",\n    content=\"My first post\",\n    author_id=author.id,\n))\n\n# Add comments\ncomment = await comment_service.create(s3_client, Comment(\n    content=\"Great post!\",\n    post_id=post.id,\n    commenter_name=\"Reader\",\n))\n\n# Delete author cascades to posts and comments\nhandler = CascadeHandler(s3_client, bucket)\nawait handler.handle_delete(author, Author._relationships)\nawait author_service.delete(s3_client, author.id)\n# Posts and comments are now deleted\n</code></pre>"},{"location":"guide-relationships.html#best-practices","title":"Best Practices","text":"<ol> <li>Define both sides - Add relationships on both models for clarity</li> <li>Use CASCADE carefully - Understand what will be deleted</li> <li>Consider PROTECT - For critical data that shouldn't be orphaned</li> <li>Load efficiently - Use resolver for batch loading</li> <li>Clean up orphans - Run periodic cleanup for DO_NOTHING relationships</li> </ol>"},{"location":"guide-storage.html","title":"File Storage Guide","text":"<p>Handle file uploads with presigned URLs for direct S3 uploads.</p>"},{"location":"guide-storage.html#overview","title":"Overview","text":"<p>S3verless provides presigned URL functionality that lets clients upload files directly to S3, bypassing your server. This reduces bandwidth, latency, and server load.</p>"},{"location":"guide-storage.html#setup","title":"Setup","text":""},{"location":"guide-storage.html#configure-upload-service","title":"Configure Upload Service","text":"<pre><code>from s3verless.storage.uploads import PresignedUploadService, UploadConfig\n\nconfig = UploadConfig(\n    max_file_size=10 * 1024 * 1024,  # 10MB\n    allowed_content_types=[\"image/jpeg\", \"image/png\", \"application/pdf\"],\n    upload_prefix=\"uploads/\",\n    expiration_seconds=3600,  # 1 hour\n)\n\nupload_service = PresignedUploadService(\"my-bucket\", config)\n</code></pre>"},{"location":"guide-storage.html#upload-flow","title":"Upload Flow","text":""},{"location":"guide-storage.html#1-generate-upload-url","title":"1. Generate Upload URL","text":"<pre><code># Server generates presigned URL\nurl_data = await upload_service.generate_upload_url(\n    s3_client,\n    filename=\"photo.jpg\",\n    content_type=\"image/jpeg\",\n    metadata={\"uploaded_by\": str(user.id)},\n)\n\n# Returns:\n# {\n#     \"url\": \"https://bucket.s3.amazonaws.com\",\n#     \"key\": \"uploads/2024/01/15/abc123.jpg\",\n#     \"fields\": {\"key\": \"...\", \"Content-Type\": \"...\", ...},\n#     \"expires_in\": 3600,\n#     \"max_size\": 10485760,\n# }\n</code></pre>"},{"location":"guide-storage.html#2-client-uploads-to-s3","title":"2. Client Uploads to S3","text":"<p>Client uses the presigned URL to upload directly:</p> <pre><code>// JavaScript client\nconst formData = new FormData();\n\n// Add all fields from the response\nObject.entries(urlData.fields).forEach(([key, value]) =&gt; {\n    formData.append(key, value);\n});\n\n// Add the file last\nformData.append('file', file);\n\n// POST to the presigned URL\nawait fetch(urlData.url, {\n    method: 'POST',\n    body: formData,\n});\n</code></pre>"},{"location":"guide-storage.html#3-confirm-upload","title":"3. Confirm Upload","text":"<p>After upload, confirm and create a record:</p> <pre><code># Server confirms the upload\nfile_record = await upload_service.confirm_upload(\n    s3_client,\n    s3_key=url_data[\"key\"],\n    uploaded_by=user.id,\n)\n\nif file_record:\n    # Upload confirmed, file_record contains metadata\n    print(f\"Uploaded: {file_record.filename}, {file_record.size} bytes\")\nelse:\n    # Upload failed or not found\n    print(\"Upload not found\")\n</code></pre>"},{"location":"guide-storage.html#download-urls","title":"Download URLs","text":"<p>Generate presigned download URLs:</p> <pre><code>download_url = await upload_service.generate_download_url(\n    s3_client,\n    s3_key=\"uploads/2024/01/15/abc123.jpg\",\n    filename=\"my-photo.jpg\",  # Suggested download name\n    expires_in=3600,\n)\n# https://bucket.s3.amazonaws.com/uploads/...?...\n</code></pre>"},{"location":"guide-storage.html#delete-files","title":"Delete Files","text":"<pre><code>deleted = await upload_service.delete_file(s3_client, s3_key)\nif deleted:\n    print(\"File deleted\")\n</code></pre>"},{"location":"guide-storage.html#fastapi-integration","title":"FastAPI Integration","text":""},{"location":"guide-storage.html#upload-endpoints","title":"Upload Endpoints","text":"<pre><code>from fastapi import APIRouter, Depends, HTTPException\nfrom pydantic import BaseModel\n\nrouter = APIRouter(prefix=\"/files\", tags=[\"files\"])\n\nclass UploadRequest(BaseModel):\n    filename: str\n    content_type: str | None = None\n\nclass UploadResponse(BaseModel):\n    url: str\n    key: str\n    fields: dict\n    expires_in: int\n\n@router.post(\"/upload-url\", response_model=UploadResponse)\nasync def get_upload_url(\n    request: UploadRequest,\n    s3_client = Depends(get_s3_client),\n    user = Depends(get_current_user),\n):\n    try:\n        data = await upload_service.generate_upload_url(\n            s3_client,\n            filename=request.filename,\n            content_type=request.content_type,\n            metadata={\"user_id\": str(user.id)},\n        )\n        return data\n    except ValueError as e:\n        raise HTTPException(400, str(e))\n\n@router.post(\"/confirm/{key:path}\")\nasync def confirm_upload(\n    key: str,\n    s3_client = Depends(get_s3_client),\n    user = Depends(get_current_user),\n):\n    file_record = await upload_service.confirm_upload(\n        s3_client, key, uploaded_by=user.id\n    )\n    if not file_record:\n        raise HTTPException(404, \"Upload not found\")\n    return {\"file_id\": str(file_record.id), \"filename\": file_record.filename}\n\n@router.get(\"/download/{file_id}\")\nasync def get_download_url(\n    file_id: str,\n    s3_client = Depends(get_s3_client),\n):\n    # Get file record\n    file_service = S3DataService(UploadedFile, bucket)\n    file_record = await file_service.get(s3_client, UUID(file_id))\n    if not file_record:\n        raise HTTPException(404, \"File not found\")\n\n    url = await upload_service.generate_download_url(\n        s3_client,\n        s3_key=file_record.s3_key,\n        filename=file_record.filename,\n    )\n    return {\"download_url\": url}\n</code></pre>"},{"location":"guide-storage.html#content-type-validation","title":"Content Type Validation","text":"<p>Restrict allowed file types:</p> <pre><code>config = UploadConfig(\n    allowed_content_types=[\n        \"image/jpeg\",\n        \"image/png\",\n        \"image/gif\",\n        \"image/webp\",\n        \"application/pdf\",\n    ],\n)\n</code></pre> <p>Attempting to upload a disallowed type raises <code>ValueError</code>.</p>"},{"location":"guide-storage.html#file-size-limits","title":"File Size Limits","text":"<pre><code>config = UploadConfig(\n    max_file_size=50 * 1024 * 1024,  # 50MB\n)\n</code></pre> <p>S3 enforces this via presigned POST conditions.</p>"},{"location":"guide-storage.html#organizing-uploads","title":"Organizing Uploads","text":"<p>Files are organized by date:</p> <pre><code>bucket/\n\u2514\u2500\u2500 uploads/\n    \u2514\u2500\u2500 2024/\n        \u2514\u2500\u2500 01/\n            \u2514\u2500\u2500 15/\n                \u251c\u2500\u2500 abc123.jpg\n                \u2514\u2500\u2500 def456.pdf\n</code></pre> <p>Custom organization:</p> <pre><code># Override key generation\nclass CustomUploadService(PresignedUploadService):\n    def _generate_key(self, filename: str) -&gt; str:\n        file_id = uuid.uuid4()\n        ext = \".\" + filename.rsplit(\".\", 1)[-1].lower() if \".\" in filename else \"\"\n        return f\"files/{file_id}{ext}\"\n</code></pre>"},{"location":"guide-storage.html#linking-files-to-models","title":"Linking Files to Models","text":""},{"location":"guide-storage.html#file-reference-field","title":"File Reference Field","text":"<pre><code>class Product(BaseS3Model):\n    name: str\n    image_id: UUID | None = None  # Reference to UploadedFile\n</code></pre>"},{"location":"guide-storage.html#with-image-url","title":"With Image URL","text":"<pre><code>@router.get(\"/products/{product_id}\")\nasync def get_product(product_id: str, s3_client = Depends(get_s3_client)):\n    product = await product_service.get(s3_client, UUID(product_id))\n\n    response = product.model_dump()\n\n    if product.image_id:\n        file_record = await file_service.get(s3_client, product.image_id)\n        if file_record:\n            response[\"image_url\"] = await upload_service.generate_download_url(\n                s3_client, file_record.s3_key, expires_in=3600\n            )\n\n    return response\n</code></pre>"},{"location":"guide-storage.html#image-processing","title":"Image Processing","text":"<p>For image processing, consider AWS Lambda triggers:</p> <pre><code># Lambda function triggered on S3 upload\ndef process_image(event, context):\n    bucket = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\n    key = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]\n\n    # Download, resize, create thumbnails\n    # Upload processed versions\n</code></pre>"},{"location":"guide-storage.html#security-considerations","title":"Security Considerations","text":"<ol> <li>Validate content types - Use <code>allowed_content_types</code></li> <li>Limit file sizes - Use <code>max_file_size</code></li> <li>Short expiry - Keep presigned URLs short-lived</li> <li>Scan uploads - Consider virus scanning for user uploads</li> <li>Private by default - Files are private unless explicitly shared</li> <li>User ownership - Track <code>uploaded_by</code> for access control</li> </ol>"},{"location":"guide-storage.html#best-practices","title":"Best Practices","text":"<ol> <li>Use presigned URLs - Don't proxy files through your server</li> <li>Confirm uploads - Verify file exists before creating records</li> <li>Handle failures - Client upload may fail, check before assuming success</li> <li>Organize files - Use date-based or user-based prefixes</li> <li>Clean up orphans - Periodically delete unconfirmed uploads</li> <li>Set appropriate TTLs - Balance security vs. convenience</li> </ol>"},{"location":"guide-testing.html","title":"Testing Guide","text":"<p>Test your S3verless applications without external dependencies.</p>"},{"location":"guide-testing.html#in-memory-s3-mock","title":"In-Memory S3 Mock","text":"<p>S3verless provides <code>InMemoryS3</code>, a fully async-compatible mock S3 client:</p> <pre><code>from s3verless.testing.mocks import InMemoryS3\n\ns3 = InMemoryS3()\n\n# Use like a real S3 client\nawait s3.create_bucket(Bucket=\"test-bucket\")\nawait s3.put_object(Bucket=\"test-bucket\", Key=\"data.json\", Body=b'{\"id\": 1}')\nresponse = await s3.get_object(Bucket=\"test-bucket\", Key=\"data.json\")\ndata = await response[\"Body\"].read()\n</code></pre>"},{"location":"guide-testing.html#context-manager","title":"Context Manager","text":"<pre><code>from s3verless.testing.mocks import mock_s3_client\n\nasync def test_something():\n    with mock_s3_client() as s3:\n        await s3.create_bucket(Bucket=\"test\")\n        # Test code...\n    # Mock is automatically cleared\n</code></pre>"},{"location":"guide-testing.html#pytest-fixtures","title":"Pytest Fixtures","text":""},{"location":"guide-testing.html#basic-fixture","title":"Basic Fixture","text":"<pre><code>import pytest\nfrom s3verless.testing.mocks import InMemoryS3\n\n@pytest.fixture\ndef s3_client():\n    \"\"\"Provide a fresh mock S3 client for each test.\"\"\"\n    s3 = InMemoryS3()\n    yield s3\n    s3.clear()\n\n@pytest.fixture\nasync def bucket(s3_client):\n    \"\"\"Create a test bucket.\"\"\"\n    await s3_client.create_bucket(Bucket=\"test-bucket\")\n    return \"test-bucket\"\n</code></pre>"},{"location":"guide-testing.html#complete-test-setup","title":"Complete Test Setup","text":"<pre><code>import pytest\nfrom s3verless.core.base import BaseS3Model\nfrom s3verless.core.service import S3DataService\nfrom s3verless.core.registry import set_base_s3_path\nfrom s3verless.testing.mocks import InMemoryS3\n\nclass Product(BaseS3Model):\n    _plural_name = \"products\"\n    name: str\n    price: float\n\n@pytest.fixture\ndef s3_client():\n    s3 = InMemoryS3()\n    yield s3\n    s3.clear()\n\n@pytest.fixture\nasync def setup(s3_client):\n    set_base_s3_path(\"test/\")\n    await s3_client.create_bucket(Bucket=\"test-bucket\")\n    return {\n        \"s3_client\": s3_client,\n        \"bucket\": \"test-bucket\",\n        \"service\": S3DataService(Product, \"test-bucket\"),\n    }\n\n@pytest.mark.asyncio\nasync def test_create_product(setup):\n    s3_client = setup[\"s3_client\"]\n    service = setup[\"service\"]\n\n    product = await service.create(\n        s3_client,\n        Product(name=\"Widget\", price=29.99)\n    )\n\n    assert product.name == \"Widget\"\n    assert product.id is not None\n</code></pre>"},{"location":"guide-testing.html#testing-crud-operations","title":"Testing CRUD Operations","text":"<pre><code>@pytest.mark.asyncio\nasync def test_crud_operations(setup):\n    s3 = setup[\"s3_client\"]\n    service = setup[\"service\"]\n\n    # Create\n    product = await service.create(s3, Product(name=\"Widget\", price=10.00))\n    assert product.id is not None\n\n    # Read\n    fetched = await service.get(s3, product.id)\n    assert fetched.name == \"Widget\"\n\n    # Update\n    fetched.price = 15.00\n    updated = await service.update(s3, product.id, fetched)\n    assert updated.price == 15.00\n\n    # Delete\n    deleted = await service.delete(s3, product.id)\n    assert deleted is True\n\n    # Verify deletion\n    fetched = await service.get(s3, product.id)\n    assert fetched is None\n</code></pre>"},{"location":"guide-testing.html#testing-queries","title":"Testing Queries","text":"<pre><code>from s3verless.core.query import Query\n\n@pytest.mark.asyncio\nasync def test_query_filter(setup):\n    s3 = setup[\"s3_client\"]\n    service = setup[\"service\"]\n    bucket = setup[\"bucket\"]\n\n    # Create test data\n    await service.create(s3, Product(name=\"Widget A\", price=10.00))\n    await service.create(s3, Product(name=\"Widget B\", price=20.00))\n    await service.create(s3, Product(name=\"Gadget\", price=30.00))\n\n    # Test filter\n    results = await (\n        Query(Product, s3, bucket)\n        .filter(name__startswith=\"Widget\")\n        .all()\n    )\n    assert len(results) == 2\n\n    # Test comparison\n    results = await (\n        Query(Product, s3, bucket)\n        .filter(price__gte=20.00)\n        .all()\n    )\n    assert len(results) == 2\n</code></pre>"},{"location":"guide-testing.html#testing-authentication","title":"Testing Authentication","text":"<pre><code>from s3verless.auth.service import S3AuthService\nfrom s3verless.core.settings import S3verlessSettings\n\n@pytest.fixture\ndef auth_service():\n    settings = S3verlessSettings(\n        aws_bucket_name=\"test-bucket\",\n        secret_key=\"test-secret-key-32-characters-long\",\n    )\n    return S3AuthService(settings)\n\n@pytest.mark.asyncio\nasync def test_user_registration(s3_client, auth_service):\n    await s3_client.create_bucket(Bucket=\"test-bucket\")\n\n    user = await auth_service.create_user(\n        s3_client,\n        username=\"testuser\",\n        email=\"test@example.com\",\n        password=\"SecurePass123!\",\n    )\n\n    assert user.username == \"testuser\"\n    assert user.email == \"test@example.com\"\n    assert user.hashed_password != \"SecurePass123!\"\n\n@pytest.mark.asyncio\nasync def test_authentication(s3_client, auth_service):\n    await s3_client.create_bucket(Bucket=\"test-bucket\")\n\n    # Create user\n    await auth_service.create_user(\n        s3_client, \"testuser\", \"test@example.com\", \"SecurePass123!\"\n    )\n\n    # Valid login\n    user = await auth_service.authenticate_user(\n        s3_client, \"testuser\", \"SecurePass123!\"\n    )\n    assert user is not None\n\n    # Invalid password\n    user = await auth_service.authenticate_user(\n        s3_client, \"testuser\", \"wrongpassword\"\n    )\n    assert user is None\n</code></pre>"},{"location":"guide-testing.html#testing-fastapi-endpoints","title":"Testing FastAPI Endpoints","text":"<pre><code>from fastapi.testclient import TestClient\nfrom httpx import AsyncClient\n\n@pytest.fixture\ndef app(s3_client):\n    \"\"\"Create test app with mock S3.\"\"\"\n    from myapp.main import create_app\n\n    app = create_app()\n    app.state.s3_client = s3_client\n    return app\n\n@pytest.mark.asyncio\nasync def test_create_product_endpoint(app, s3_client):\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        response = await client.post(\n            \"/products\",\n            json={\"name\": \"Widget\", \"price\": 29.99},\n        )\n\n    assert response.status_code == 201\n    data = response.json()\n    assert data[\"name\"] == \"Widget\"\n    assert \"id\" in data\n</code></pre>"},{"location":"guide-testing.html#testing-migrations","title":"Testing Migrations","text":"<pre><code>from s3verless.migrations.base import Migration\nfrom s3verless.migrations.runner import MigrationRunner\n\n@pytest.mark.asyncio\nasync def test_migration(s3_client):\n    await s3_client.create_bucket(Bucket=\"test-bucket\")\n\n    # Create initial data\n    await s3_client.put_object(\n        Bucket=\"test-bucket\",\n        Key=\"test/products/123.json\",\n        Body=b'{\"id\": \"123\", \"name\": \"Widget\"}',\n    )\n\n    # Define migration\n    migration = Migration(\n        version=\"0001\",\n        model_name=\"Product\",\n        description=\"Add price field\",\n        apply=lambda d: {**d, \"price\": 0.0},\n        reversible=True,\n    )\n\n    runner = MigrationRunner(s3_client, \"test-bucket\")\n    runner.register(migration)\n\n    # Run migration\n    results = await runner.run_pending()\n    assert len(results) == 1\n    assert results[0][\"objects_transformed\"] == 1\n\n    # Verify data was migrated\n    response = await s3_client.get_object(\n        Bucket=\"test-bucket\",\n        Key=\"test/products/123.json\",\n    )\n    data = await response[\"Body\"].read()\n    assert b'\"price\": 0.0' in data\n</code></pre>"},{"location":"guide-testing.html#test-data-helpers","title":"Test Data Helpers","text":""},{"location":"guide-testing.html#seed-data","title":"Seed Data","text":"<pre><code>from s3verless.seeding.loader import SeedLoader\n\n@pytest.mark.asyncio\nasync def test_with_seed_data(s3_client):\n    await s3_client.create_bucket(Bucket=\"test-bucket\")\n\n    # Seed from list\n    await SeedLoader.seed_model(\n        s3_client,\n        Product,\n        [\n            {\"name\": \"Widget A\", \"price\": 10.00},\n            {\"name\": \"Widget B\", \"price\": 20.00},\n        ],\n        \"test-bucket\",\n    )\n\n    # Verify\n    service = S3DataService(Product, \"test-bucket\")\n    products, _ = await service.list_by_prefix(s3_client)\n    assert len(products) == 2\n</code></pre>"},{"location":"guide-testing.html#factory-pattern","title":"Factory Pattern","text":"<pre><code>import factory\nfrom uuid import uuid4\n\nclass ProductFactory:\n    @staticmethod\n    def build(**kwargs):\n        defaults = {\n            \"name\": f\"Product {uuid4().hex[:6]}\",\n            \"price\": 9.99,\n        }\n        return Product(**{**defaults, **kwargs})\n\n    @staticmethod\n    async def create(s3_client, service, **kwargs):\n        product = ProductFactory.build(**kwargs)\n        return await service.create(s3_client, product)\n</code></pre>"},{"location":"guide-testing.html#best-practices","title":"Best Practices","text":"<ol> <li>Use fixtures - Share setup code across tests</li> <li>Isolate tests - Clear mock between tests</li> <li>Test edge cases - Empty results, validation errors</li> <li>Test async properly - Use <code>pytest.mark.asyncio</code></li> <li>Mock external services - Not just S3, but any external dependency</li> <li>Test error paths - Ensure proper error handling</li> <li>Keep tests fast - In-memory mock enables fast iteration</li> </ol>"}]}